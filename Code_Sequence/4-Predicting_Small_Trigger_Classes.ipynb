{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Predicting Small Trigger Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(99)\n",
    "RANDOM_STATE = 99\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reshaped_lemmatized():\n",
    "    # Import the CSV file\n",
    "    df = pd.read_csv('../data/reshaped_lemmatized.csv').drop(columns = ('Unnamed: 0'), axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling_data_set(df, threshold):\n",
    "    #Total sum per row: \n",
    "    downsampling_set = df\n",
    "    downsampling_set.loc[:,'Total'] = downsampling_set.sum(axis=1)\n",
    "\n",
    "    # select only Sentences with 1 or 2 triggers\n",
    "    downsampling_set = downsampling_set[downsampling_set['Total'].isin([1,2])]\n",
    "\n",
    "    \n",
    "    # isolate the trigger columns to sample from\n",
    "    n = threshold\n",
    "    trigger_cols = downsampling_set.drop(['Document', 'Sentence', 'SentenceLemmas', 'SentenceTokens'], axis=1).sum(axis=0)\n",
    "    trigger_cols = trigger_cols.where(lambda x: x > n).dropna()\n",
    "    trigger_cols = [t for t in list(trigger_cols.index) if t not in ['Total', 'nontrigger', 'unspecified']]\n",
    "    nontrigger_cols = ['nontrigger']\n",
    "    \n",
    "    # randomly sample n rows from the selected trigger columns without replacement - samples is the training set\n",
    "    init = True\n",
    "\n",
    "    for col in trigger_cols:\n",
    "        temp_col = downsampling_set[downsampling_set[col] == 1]\n",
    "        sampled_col = resample(temp_col, replace = False, n_samples = n, random_state = RANDOM_STATE)\n",
    "        if init:\n",
    "            samples = sampled_col\n",
    "            init = False\n",
    "        else:\n",
    "            samples = pd.concat([samples,sampled_col])\n",
    "            \n",
    "    n_unspecified = samples.shape[0] # Prepare to randomaly collect nontrigger data of an equivalent size\n",
    "    for col in nontrigger_cols:\n",
    "        temp_col = downsampling_set[downsampling_set[col] == 1]\n",
    "        nontrigger_sampled_col = resample(temp_col, replace = False, n_samples = n_unspecified, random_state = RANDOM_STATE)\n",
    "        samples = pd.concat([samples, nontrigger_sampled_col])\n",
    "        \n",
    "    # remove these rows from the main data set - select index and remove by index\n",
    "    rmv_index = list(samples.index)\n",
    "    filtered = df.drop(rmv_index, axis='index') # This will become our Test Set\n",
    "    \n",
    "    # make 'is trigger' column\n",
    "    samples['istrigger'] = np.where(samples['nontrigger'] > 0, 0, 1)\n",
    "    filtered['istrigger'] = np.where(filtered['nontrigger'] > 0, 0, 1)\n",
    "    \n",
    "    # Check which trigger types were included in the training set\n",
    "#    in_train_set = (downsampling_set.drop(['Document', 'Sentence', 'Total', 'unspecified'], axis=1).sum(axis=0) > n).to_frame()\n",
    "    \n",
    "    return samples, filtered # Samples will be the Training Set, Filtered will be the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate Stopwords\n",
    "def get_stopwords():\n",
    "    # might need space\n",
    "    short_stopwords = ['the', 'to', 'of', 'be', 'and', 'in', 'a', 'marriott']\n",
    "    short_stopwords2 = ['the', 'and', 'a', 'to', 'it', 'be', 'for', 'with', 'that', 'marriott']\n",
    "    stopwords = list(STOP_WORDS) + ['marriott'];\n",
    "\n",
    "    return short_stopwords, short_stopwords2, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data for each target column (trigger type)\n",
    "def run_model(df, threshold):\n",
    "    downsampling_data_set(df, threshold)\n",
    "    short_stopwords, short_stopwords2, stopwords = get_stopwords()\n",
    "    \n",
    "    X_train = samples['SentenceLemmas']\n",
    "    y_train = samples['istrigger']\n",
    "    X_test = filtered['SentenceLemmas']\n",
    "    y_test = filtered['istrigger']\n",
    "\n",
    "    y_train = y_train.astype('int')\n",
    "    y_test = y_test.astype('int')\n",
    "\n",
    "    \n",
    "    train_index = samples.index\n",
    "    test_index = filtered.index\n",
    "    \n",
    "    pipe_cvec = Pipeline([('cvec', CountVectorizer()), ('lr', LogisticRegression(solver = 'liblinear', random_state = RANDOM_STATE))]) \n",
    "    cvec_params = {\n",
    "        'cvec__ngram_range': [(1,2), (1,3), (1,4), (1,5)],\n",
    "        'cvec__stop_words': [short_stopwords, short_stopwords2, stopwords],  \n",
    "        'cvec__max_features': [100, 200, 400, 600, 1000],\n",
    "        'cvec__min_df': [2],\n",
    "        'cvec__max_df': [.99],\n",
    "        }\n",
    "\n",
    "    gs_cvec = GridSearchCV(pipe_cvec, param_grid = cvec_params, cv = 3, scoring = 'roc_auc')\n",
    "\n",
    "    # Start the timer.\n",
    "    t0 = time.time()\n",
    "\n",
    "    results_cvec = gs_cvec.fit(X_train, y_train)\n",
    "    return results_cvec, X_train, y_train, X_test, y_test, train_index, test_index\n",
    "\n",
    "    print(f'Seconds elapsed for fitting: {(time.time() - t0):.3f}')\n",
    "    print(f'Training score is {results_cvec.score(X_train, y_train):.3f}')\n",
    "    print(f'Test score is {results_cvec.score(X_test, y_test):.3f}')\n",
    "    \n",
    "    # How many seconds elapsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassification(results_cvec, X_train, y_train, X_test, y_test, train_index, test_index, filtered):\n",
    "    best_model = results_cvec.best_estimator_\n",
    "    preds = best_model.predict(X_test)\n",
    "    pred_proba = [i[1] for i in results_cvec.predict_proba(X_test)]\n",
    "    pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})\n",
    "    result_cols = ['index', 'prediction', 'actual', 'model_input']\n",
    "    results = pd.DataFrame({'index': list(test_index),'prediction': list(preds), 'actual': list(y_test), 'model_input': list(X_test)})\n",
    "    results.set_index('index', inplace = True)\n",
    "    misclassified = results[results['prediction'] != results['actual']]\n",
    "    misclassified = misclassified.merge(df, how = 'left', left_index = True, right_index = True)\n",
    "    misclassified = misclassified[['prediction', 'actual', 'model_input', 'Document', 'Sentence',\n",
    "       'loan_default', 'aggregate_dscr_fall', 'dscr_fall', 'unspecified',\n",
    "       'debt_yield_fall', 'aggregate_debt_yield_fall', 'mezzanine_default',\n",
    "       'tenant_failure', 'mezzanine_outstanding', 'operator_termination', 'bankruptcy', 'sponsor_termination', 'renovations', 'nontrigger', 'sff', 'delayed_repayment']]\n",
    "    full_test_set = filtered.drop(['Document', 'Sentence', 'Total', 'istrigger', 'SentenceTokens', 'SentenceLemmas'], axis = 1).sum(axis = 0).to_frame()\n",
    "    misclassified_test_set = misclassified.drop(['prediction', 'actual', 'Document', 'Sentence', 'model_input'], axis=1).sum(axis=0).to_frame()\n",
    "    misclassified_results = full_test_set.merge(misclassified_test_set, left_index = True, right_index = True)\n",
    "    misclassified_results.rename(columns = {'0_x': 'full_test_set', '0_y': 'num_misclassified'}, inplace = True)\n",
    "    misclassified_results['percent_misclassified'] = 100 * misclassified_results['num_misclassified'] / misclassified_results['full_test_set']\n",
    "    misclassified_results['percent_misclassified'] = misclassified_results['percent_misclassified'].round(1)\n",
    "    misclassified_results = misclassified_results.merge(in_train_set, left_index = True, right_index = True)\n",
    "    misclassified_results.rename(columns = {0: 'in_train_set'}, inplace = True)\n",
    "    misclassified_results['in_train_set'] = misclassified_results['in_train_set'].map({True: 'yes', False: 'no'})\n",
    "    return misclassified_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform modeling steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8aeffb39b2a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownsampling_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults_cvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmisclassified_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_cvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-0d27f639d7c9>\u001b[0m in \u001b[0;36mmisclassification\u001b[0;34m(results_cvec, X_train, y_train, X_test, y_test, train_index, test_index, filtered)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmisclassified_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percent_misclassified'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmisclassified_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_misclassified'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmisclassified_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_test_set'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmisclassified_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percent_misclassified'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisclassified_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percent_misclassified'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmisclassified_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisclassified_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mmisclassified_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'in_train_set'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmisclassified_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in_train_set'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisclassified_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in_train_set'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'yes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'no'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'in_train_set' is not defined"
     ]
    }
   ],
   "source": [
    "df = get_reshaped_lemmatized()\n",
    "samples, filtered = downsampling_data_set(df, 10)\n",
    "results_cvec, X_train, y_train, X_test, y_test, train_index, test_index = run_model(df, 10)\n",
    "misclassified_results = misclassification(results_cvec, X_train, y_train, X_test, y_test, train_index, test_index, filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
