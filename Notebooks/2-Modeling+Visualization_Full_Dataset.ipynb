{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Modeling of full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes in the reshaped data, with lemmatized sentences from the prior 'Data Cleaning and NLP Preprocessing' notebook & fully models the dataset, returning a dataframe of all modeling inputs, hyperparameters and results.\n",
    "\n",
    "Steps performed by the included functions:\n",
    "\n",
    "\n",
    "- import dataset that has been preprocessed with Spacy and reshaped to have each document-sentence represented only once \n",
    "- train-test-split the preprocessed dataset & return a dictionary of processed and split data that is ready for modeling\n",
    "- create stopword lists\n",
    "- run modeling via logistic or random forest regression methods (defaults are set for logistic regression) - modeling is via gridsearch, and a dataframe is returned, including all modeling inputs, hyperparameters and results.\n",
    "- create a coefficient/beta bar chart for each Cash Trap Trigger category\n",
    "- create a confusion matrix for each Cash Trap Trigger category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(99)\n",
    "RANDOM_STATE = 99\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reshaped_lemmatized():\n",
    "    # Import the CSV file\n",
    "    df = pd.read_csv('../data/reshaped_lemmatized.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data for each target column (trigger type)\n",
    "def get_split_data(df, target_info):\n",
    "    # extract target name\n",
    "    target = target_info['target']\n",
    "    model_input  = target_info['model_input']\n",
    "    \n",
    "    # create X, Y\n",
    "    X = df[model_input]\n",
    "    y = df[target]\n",
    "    indices = df.index\n",
    "\n",
    "    print(f\"Number of distinct labeled {target} document/sentence combinations within the full data set: {y.value_counts()[1]}\")   \n",
    "    \n",
    "    y = y.astype('int')\n",
    "\n",
    "    # run test, train split\n",
    "    X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size = 0.3, stratify = y, random_state = RANDOM_STATE)\n",
    "\n",
    "    \n",
    "    # create output dictionary\n",
    "    split_data = {}\n",
    "    split_data['X_train'] = X_train\n",
    "    split_data['X_test'] = X_test\n",
    "    split_data['y_train'] = y_train\n",
    "    split_data['y_test'] = y_test\n",
    "    split_data['indices_train'] = indices_train\n",
    "    split_data['indices_test'] = indices_test\n",
    "    \n",
    "    # Return the train-test-split data in a dictionary form\n",
    "    return split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate Stopwords\n",
    "def get_stopwords():\n",
    "    # might need space\n",
    "    short_stopwords = ['the', 'to', 'of', 'be', 'and', 'in', 'a', 'marriott']\n",
    "    short_stopwords2 = ['the', 'and', 'a', 'to', 'it', 'be', 'for', 'with', 'that', 'marriott']\n",
    "    stopwords = list(STOP_WORDS) + ['marriott']\n",
    "\n",
    "    return short_stopwords, short_stopwords2, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model with the chosen model and metric\n",
    "def run_model(split_data, target_info):\n",
    "\n",
    "    # get stopwords\n",
    "    short_stopwords, short_stopwords2, stopwords = get_stopwords()\n",
    "    \n",
    "    # set pipeline according to the selected model:\n",
    "    if target_info['model'] == 'lr':\n",
    "        # Define CVEC + Logistic Regression Pipeline\n",
    "        pipe = Pipeline([('cvec', CountVectorizer()), ('lr', LogisticRegression(solver = 'liblinear', random_state = RANDOM_STATE))])\n",
    "        params = {\n",
    "            'cvec__ngram_range': [(1,2), (1,3), (1,4), (1,5), (1,6), (1,7)],\n",
    "            'cvec__stop_words': [short_stopwords, short_stopwords2, stopwords],  \n",
    "            'cvec__max_features': [100, 200, 400, 600, 1000],\n",
    "            'cvec__min_df': [2],\n",
    "            'cvec__max_df': [.99],\n",
    "            }\n",
    "\n",
    "    elif target_info['model'] == 'rf':\n",
    "        # Define CVEC + Logistic Regression Pipeline\n",
    "        pipe = Pipeline([('cvec', CountVectorizer()), ('rf', RandomForestClassifier(random_state = RANDOM_STATE, n_jobs = 2))])\n",
    "        params = {\n",
    "            'cvec__ngram_range': [(1,2), (1,3), (1,4), (1,5)],\n",
    "            'cvec__stop_words': [short_stopwords, short_stopwords2, stopwords],  \n",
    "            'cvec__max_features': [100, 200, 400, 800],\n",
    "            'cvec__min_df': [2],\n",
    "            'cvec__max_df': [.99],\n",
    "            'rf__max_depth': [4,5, 6],\n",
    "            'rf__min_samples_split': [2,3],\n",
    "            'rf__min_samples_leaf': [10, 12]\n",
    "            }\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print('Error: did not specify model')\n",
    "\n",
    "    # define pipeline\n",
    "    gs_model = GridSearchCV(pipe, param_grid = params, cv = 3, scoring = target_info['metric'])\n",
    "\n",
    "    # Start the timer.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # extract X_train and y_train\n",
    "    X_train = split_data['X_train']\n",
    "    y_train = split_data['y_train']\n",
    "    \n",
    "    # run pipeline\n",
    "    model_result = gs_model.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Seconds elapsed for fitting: {(time.time() - t0):.3f}\") # How many seconds elapsed.   \n",
    "    return model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform all modeling steps for all targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in advance, adjust parameters/metrics for any particular modeling target in the target_dict below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nontrigger: creating Train-Test split\n",
      "Number of distinct labeled nontrigger document/sentence combinations within the full data set: 1030\n",
      "Model fit in progress: {'target': 'nontrigger', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 144.864\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': ['something', 'whereafter', 'are', 'full', 'of', 'neither', 'since', 'sixty', 'twelve', 'here', 'it', 'she', 'a', 'do', 'everyone', 'this', 'bottom', 'used', 'anywhere', 'never', 'the', 'mine', 'thru', 'either', 'give', 'serious', 'more', 'my', 'seems', 'just', 'i', 'formerly', 'namely', 'through', 'why', 'empty', 'yet', 'mostly', 'if', 'they', 'will', 'sometime', 'without', 'amount', 'get', 'has', 'nine', 'quite', 'does', 'though', 'whereupon', 'very', 'sometimes', 'whose', 'eleven', 'otherwise', 'side', 'made', 'me', 'hence', 'however', 'next', 'nor', 'whatever', 'third', 'themselves', 'seeming', 'him', 'back', 'did', 'herself', 'on', 'afterwards', 'their', 'thereupon', 'few', 'further', 'under', 'nobody', 'what', 'may', 'myself', 'then', 'again', 'around', 'that', 'after', 'keep', 'as', 'how', 'therein', 'behind', 'across', 're', 'down', 'really', 'alone', 'most', 'being', 'into', 'nowhere', 'among', 'its', 'ours', 'part', 'per', 'almost', 'below', 'we', 'forty', 'together', 'also', 'at', 'while', 'once', 'such', 'herein', 'else', 'both', 'go', 'front', 'already', 'there', 'unless', 'anyhow', 'his', 'ever', 'anything', 'indeed', 'although', 'call', 'before', 'nevertheless', 'each', 'those', 'an', 'whether', 'throughout', 'done', 'two', 'who', 'whole', 'rather', 'out', 'yours', 'take', 'another', 'ca', 'nothing', 'none', 'by', 'onto', 'any', 'between', 'over', 'much', 'eight', 'somewhere', 'be', 'first', 'latterly', 'towards', 'some', 'perhaps', 'amongst', 'whenever', 'wherever', 'everything', 'with', 'now', 'himself', 'these', 'which', 'for', 'in', 'was', 'would', 'them', 'all', 'hundred', 'not', 'even', 'yourselves', 'many', 'than', 'to', 'enough', 'hereafter', 'within', 'fifteen', 'beforehand', 'and', 'from', 'cannot', 'own', 'wherein', 'top', 'former', 'thereafter', 'he', 'several', 'say', 'us', 'our', 'along', 'someone', 'become', 'besides', 'fifty', 'itself', 'beyond', 'had', 'put', 'must', 'see', 'because', 'about', 'name', 'other', 'toward', 'where', 'five', 'via', 'various', 'whoever', 'off', 'can', 'whence', 'or', 'ourselves', 'noone', 'whereas', 'regarding', 'been', 'upon', 'hers', 'no', 'when', 'whereby', 'during', 'twenty', 'thereby', 'beside', 'have', 'seemed', 'often', 'hereby', 'please', 'same', 'ten', 'up', 'least', 'became', 'only', 'against', 'due', 'four', 'make', 'still', 'whom', 'latter', 'one', 'others', 'show', 'elsewhere', 'too', 'am', 'could', 'doing', 'last', 'should', 'every', 'were', 'using', 'seem', 'therefore', 'is', 'but', 'thence', 'except', 'three', 'less', 'anyone', 'move', 'well', 'your', 'somehow', 'becoming', 'everywhere', 'so', 'you', 'above', 'yourself', 'hereupon', 'until', 'becomes', 'anyway', 'always', 'thus', 'whither', 'might', 'six', 'moreover', 'meanwhile', 'her', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.987\n",
      "Nontrigger roc_auc Train score: 1.000\n",
      "Nontrigger roc_auc Test score: 0.986\n",
      "\n",
      "\n",
      "Loan Default: creating Train-Test split\n",
      "Number of distinct labeled loan_default document/sentence combinations within the full data set: 553\n",
      "Model fit in progress: {'target': 'loan_default', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 143.416\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 400, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 7), 'cvec__stop_words': ['the', 'and', 'a', 'to', 'it', 'be', 'for', 'with', 'that', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.982\n",
      "Loan Default roc_auc Train score: 0.999\n",
      "Loan Default roc_auc Test score: 0.991\n",
      "\n",
      "\n",
      "Unspecified: creating Train-Test split\n",
      "Number of distinct labeled unspecified document/sentence combinations within the full data set: 498\n",
      "Model fit in progress: {'target': 'unspecified', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 153.444\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['something', 'whereafter', 'are', 'full', 'of', 'neither', 'since', 'sixty', 'twelve', 'here', 'it', 'she', 'a', 'do', 'everyone', 'this', 'bottom', 'used', 'anywhere', 'never', 'the', 'mine', 'thru', 'either', 'give', 'serious', 'more', 'my', 'seems', 'just', 'i', 'formerly', 'namely', 'through', 'why', 'empty', 'yet', 'mostly', 'if', 'they', 'will', 'sometime', 'without', 'amount', 'get', 'has', 'nine', 'quite', 'does', 'though', 'whereupon', 'very', 'sometimes', 'whose', 'eleven', 'otherwise', 'side', 'made', 'me', 'hence', 'however', 'next', 'nor', 'whatever', 'third', 'themselves', 'seeming', 'him', 'back', 'did', 'herself', 'on', 'afterwards', 'their', 'thereupon', 'few', 'further', 'under', 'nobody', 'what', 'may', 'myself', 'then', 'again', 'around', 'that', 'after', 'keep', 'as', 'how', 'therein', 'behind', 'across', 're', 'down', 'really', 'alone', 'most', 'being', 'into', 'nowhere', 'among', 'its', 'ours', 'part', 'per', 'almost', 'below', 'we', 'forty', 'together', 'also', 'at', 'while', 'once', 'such', 'herein', 'else', 'both', 'go', 'front', 'already', 'there', 'unless', 'anyhow', 'his', 'ever', 'anything', 'indeed', 'although', 'call', 'before', 'nevertheless', 'each', 'those', 'an', 'whether', 'throughout', 'done', 'two', 'who', 'whole', 'rather', 'out', 'yours', 'take', 'another', 'ca', 'nothing', 'none', 'by', 'onto', 'any', 'between', 'over', 'much', 'eight', 'somewhere', 'be', 'first', 'latterly', 'towards', 'some', 'perhaps', 'amongst', 'whenever', 'wherever', 'everything', 'with', 'now', 'himself', 'these', 'which', 'for', 'in', 'was', 'would', 'them', 'all', 'hundred', 'not', 'even', 'yourselves', 'many', 'than', 'to', 'enough', 'hereafter', 'within', 'fifteen', 'beforehand', 'and', 'from', 'cannot', 'own', 'wherein', 'top', 'former', 'thereafter', 'he', 'several', 'say', 'us', 'our', 'along', 'someone', 'become', 'besides', 'fifty', 'itself', 'beyond', 'had', 'put', 'must', 'see', 'because', 'about', 'name', 'other', 'toward', 'where', 'five', 'via', 'various', 'whoever', 'off', 'can', 'whence', 'or', 'ourselves', 'noone', 'whereas', 'regarding', 'been', 'upon', 'hers', 'no', 'when', 'whereby', 'during', 'twenty', 'thereby', 'beside', 'have', 'seemed', 'often', 'hereby', 'please', 'same', 'ten', 'up', 'least', 'became', 'only', 'against', 'due', 'four', 'make', 'still', 'whom', 'latter', 'one', 'others', 'show', 'elsewhere', 'too', 'am', 'could', 'doing', 'last', 'should', 'every', 'were', 'using', 'seem', 'therefore', 'is', 'but', 'thence', 'except', 'three', 'less', 'anyone', 'move', 'well', 'your', 'somehow', 'becoming', 'everywhere', 'so', 'you', 'above', 'yourself', 'hereupon', 'until', 'becomes', 'anyway', 'always', 'thus', 'whither', 'might', 'six', 'moreover', 'meanwhile', 'her', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.965\n",
      "Unspecified roc_auc Train score: 1.000\n",
      "Unspecified roc_auc Test score: 0.964\n",
      "\n",
      "\n",
      "Debt Yield Fall: creating Train-Test split\n",
      "Number of distinct labeled debt_yield_fall document/sentence combinations within the full data set: 188\n",
      "Model fit in progress: {'target': 'debt_yield_fall', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 141.343\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 200, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': ['something', 'whereafter', 'are', 'full', 'of', 'neither', 'since', 'sixty', 'twelve', 'here', 'it', 'she', 'a', 'do', 'everyone', 'this', 'bottom', 'used', 'anywhere', 'never', 'the', 'mine', 'thru', 'either', 'give', 'serious', 'more', 'my', 'seems', 'just', 'i', 'formerly', 'namely', 'through', 'why', 'empty', 'yet', 'mostly', 'if', 'they', 'will', 'sometime', 'without', 'amount', 'get', 'has', 'nine', 'quite', 'does', 'though', 'whereupon', 'very', 'sometimes', 'whose', 'eleven', 'otherwise', 'side', 'made', 'me', 'hence', 'however', 'next', 'nor', 'whatever', 'third', 'themselves', 'seeming', 'him', 'back', 'did', 'herself', 'on', 'afterwards', 'their', 'thereupon', 'few', 'further', 'under', 'nobody', 'what', 'may', 'myself', 'then', 'again', 'around', 'that', 'after', 'keep', 'as', 'how', 'therein', 'behind', 'across', 're', 'down', 'really', 'alone', 'most', 'being', 'into', 'nowhere', 'among', 'its', 'ours', 'part', 'per', 'almost', 'below', 'we', 'forty', 'together', 'also', 'at', 'while', 'once', 'such', 'herein', 'else', 'both', 'go', 'front', 'already', 'there', 'unless', 'anyhow', 'his', 'ever', 'anything', 'indeed', 'although', 'call', 'before', 'nevertheless', 'each', 'those', 'an', 'whether', 'throughout', 'done', 'two', 'who', 'whole', 'rather', 'out', 'yours', 'take', 'another', 'ca', 'nothing', 'none', 'by', 'onto', 'any', 'between', 'over', 'much', 'eight', 'somewhere', 'be', 'first', 'latterly', 'towards', 'some', 'perhaps', 'amongst', 'whenever', 'wherever', 'everything', 'with', 'now', 'himself', 'these', 'which', 'for', 'in', 'was', 'would', 'them', 'all', 'hundred', 'not', 'even', 'yourselves', 'many', 'than', 'to', 'enough', 'hereafter', 'within', 'fifteen', 'beforehand', 'and', 'from', 'cannot', 'own', 'wherein', 'top', 'former', 'thereafter', 'he', 'several', 'say', 'us', 'our', 'along', 'someone', 'become', 'besides', 'fifty', 'itself', 'beyond', 'had', 'put', 'must', 'see', 'because', 'about', 'name', 'other', 'toward', 'where', 'five', 'via', 'various', 'whoever', 'off', 'can', 'whence', 'or', 'ourselves', 'noone', 'whereas', 'regarding', 'been', 'upon', 'hers', 'no', 'when', 'whereby', 'during', 'twenty', 'thereby', 'beside', 'have', 'seemed', 'often', 'hereby', 'please', 'same', 'ten', 'up', 'least', 'became', 'only', 'against', 'due', 'four', 'make', 'still', 'whom', 'latter', 'one', 'others', 'show', 'elsewhere', 'too', 'am', 'could', 'doing', 'last', 'should', 'every', 'were', 'using', 'seem', 'therefore', 'is', 'but', 'thence', 'except', 'three', 'less', 'anyone', 'move', 'well', 'your', 'somehow', 'becoming', 'everywhere', 'so', 'you', 'above', 'yourself', 'hereupon', 'until', 'becomes', 'anyway', 'always', 'thus', 'whither', 'might', 'six', 'moreover', 'meanwhile', 'her', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.975\n",
      "Debt Yield Fall roc_auc Train score: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debt Yield Fall roc_auc Test score: 0.997\n",
      "\n",
      "\n",
      "Mezzanine Default: creating Train-Test split\n",
      "Number of distinct labeled mezzanine_default document/sentence combinations within the full data set: 72\n",
      "Model fit in progress: {'target': 'mezzanine_default', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 145.851\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 100, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['something', 'whereafter', 'are', 'full', 'of', 'neither', 'since', 'sixty', 'twelve', 'here', 'it', 'she', 'a', 'do', 'everyone', 'this', 'bottom', 'used', 'anywhere', 'never', 'the', 'mine', 'thru', 'either', 'give', 'serious', 'more', 'my', 'seems', 'just', 'i', 'formerly', 'namely', 'through', 'why', 'empty', 'yet', 'mostly', 'if', 'they', 'will', 'sometime', 'without', 'amount', 'get', 'has', 'nine', 'quite', 'does', 'though', 'whereupon', 'very', 'sometimes', 'whose', 'eleven', 'otherwise', 'side', 'made', 'me', 'hence', 'however', 'next', 'nor', 'whatever', 'third', 'themselves', 'seeming', 'him', 'back', 'did', 'herself', 'on', 'afterwards', 'their', 'thereupon', 'few', 'further', 'under', 'nobody', 'what', 'may', 'myself', 'then', 'again', 'around', 'that', 'after', 'keep', 'as', 'how', 'therein', 'behind', 'across', 're', 'down', 'really', 'alone', 'most', 'being', 'into', 'nowhere', 'among', 'its', 'ours', 'part', 'per', 'almost', 'below', 'we', 'forty', 'together', 'also', 'at', 'while', 'once', 'such', 'herein', 'else', 'both', 'go', 'front', 'already', 'there', 'unless', 'anyhow', 'his', 'ever', 'anything', 'indeed', 'although', 'call', 'before', 'nevertheless', 'each', 'those', 'an', 'whether', 'throughout', 'done', 'two', 'who', 'whole', 'rather', 'out', 'yours', 'take', 'another', 'ca', 'nothing', 'none', 'by', 'onto', 'any', 'between', 'over', 'much', 'eight', 'somewhere', 'be', 'first', 'latterly', 'towards', 'some', 'perhaps', 'amongst', 'whenever', 'wherever', 'everything', 'with', 'now', 'himself', 'these', 'which', 'for', 'in', 'was', 'would', 'them', 'all', 'hundred', 'not', 'even', 'yourselves', 'many', 'than', 'to', 'enough', 'hereafter', 'within', 'fifteen', 'beforehand', 'and', 'from', 'cannot', 'own', 'wherein', 'top', 'former', 'thereafter', 'he', 'several', 'say', 'us', 'our', 'along', 'someone', 'become', 'besides', 'fifty', 'itself', 'beyond', 'had', 'put', 'must', 'see', 'because', 'about', 'name', 'other', 'toward', 'where', 'five', 'via', 'various', 'whoever', 'off', 'can', 'whence', 'or', 'ourselves', 'noone', 'whereas', 'regarding', 'been', 'upon', 'hers', 'no', 'when', 'whereby', 'during', 'twenty', 'thereby', 'beside', 'have', 'seemed', 'often', 'hereby', 'please', 'same', 'ten', 'up', 'least', 'became', 'only', 'against', 'due', 'four', 'make', 'still', 'whom', 'latter', 'one', 'others', 'show', 'elsewhere', 'too', 'am', 'could', 'doing', 'last', 'should', 'every', 'were', 'using', 'seem', 'therefore', 'is', 'but', 'thence', 'except', 'three', 'less', 'anyone', 'move', 'well', 'your', 'somehow', 'becoming', 'everywhere', 'so', 'you', 'above', 'yourself', 'hereupon', 'until', 'becomes', 'anyway', 'always', 'thus', 'whither', 'might', 'six', 'moreover', 'meanwhile', 'her', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.949\n",
      "Mezzanine Default roc_auc Train score: 1.000\n",
      "Mezzanine Default roc_auc Test score: 0.995\n",
      "\n",
      "\n",
      "Bankruptcy: creating Train-Test split\n",
      "Number of distinct labeled bankruptcy document/sentence combinations within the full data set: 44\n",
      "Model fit in progress: {'target': 'bankruptcy', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 142.702\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 200, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 5), 'cvec__stop_words': ['something', 'whereafter', 'are', 'full', 'of', 'neither', 'since', 'sixty', 'twelve', 'here', 'it', 'she', 'a', 'do', 'everyone', 'this', 'bottom', 'used', 'anywhere', 'never', 'the', 'mine', 'thru', 'either', 'give', 'serious', 'more', 'my', 'seems', 'just', 'i', 'formerly', 'namely', 'through', 'why', 'empty', 'yet', 'mostly', 'if', 'they', 'will', 'sometime', 'without', 'amount', 'get', 'has', 'nine', 'quite', 'does', 'though', 'whereupon', 'very', 'sometimes', 'whose', 'eleven', 'otherwise', 'side', 'made', 'me', 'hence', 'however', 'next', 'nor', 'whatever', 'third', 'themselves', 'seeming', 'him', 'back', 'did', 'herself', 'on', 'afterwards', 'their', 'thereupon', 'few', 'further', 'under', 'nobody', 'what', 'may', 'myself', 'then', 'again', 'around', 'that', 'after', 'keep', 'as', 'how', 'therein', 'behind', 'across', 're', 'down', 'really', 'alone', 'most', 'being', 'into', 'nowhere', 'among', 'its', 'ours', 'part', 'per', 'almost', 'below', 'we', 'forty', 'together', 'also', 'at', 'while', 'once', 'such', 'herein', 'else', 'both', 'go', 'front', 'already', 'there', 'unless', 'anyhow', 'his', 'ever', 'anything', 'indeed', 'although', 'call', 'before', 'nevertheless', 'each', 'those', 'an', 'whether', 'throughout', 'done', 'two', 'who', 'whole', 'rather', 'out', 'yours', 'take', 'another', 'ca', 'nothing', 'none', 'by', 'onto', 'any', 'between', 'over', 'much', 'eight', 'somewhere', 'be', 'first', 'latterly', 'towards', 'some', 'perhaps', 'amongst', 'whenever', 'wherever', 'everything', 'with', 'now', 'himself', 'these', 'which', 'for', 'in', 'was', 'would', 'them', 'all', 'hundred', 'not', 'even', 'yourselves', 'many', 'than', 'to', 'enough', 'hereafter', 'within', 'fifteen', 'beforehand', 'and', 'from', 'cannot', 'own', 'wherein', 'top', 'former', 'thereafter', 'he', 'several', 'say', 'us', 'our', 'along', 'someone', 'become', 'besides', 'fifty', 'itself', 'beyond', 'had', 'put', 'must', 'see', 'because', 'about', 'name', 'other', 'toward', 'where', 'five', 'via', 'various', 'whoever', 'off', 'can', 'whence', 'or', 'ourselves', 'noone', 'whereas', 'regarding', 'been', 'upon', 'hers', 'no', 'when', 'whereby', 'during', 'twenty', 'thereby', 'beside', 'have', 'seemed', 'often', 'hereby', 'please', 'same', 'ten', 'up', 'least', 'became', 'only', 'against', 'due', 'four', 'make', 'still', 'whom', 'latter', 'one', 'others', 'show', 'elsewhere', 'too', 'am', 'could', 'doing', 'last', 'should', 'every', 'were', 'using', 'seem', 'therefore', 'is', 'but', 'thence', 'except', 'three', 'less', 'anyone', 'move', 'well', 'your', 'somehow', 'becoming', 'everywhere', 'so', 'you', 'above', 'yourself', 'hereupon', 'until', 'becomes', 'anyway', 'always', 'thus', 'whither', 'might', 'six', 'moreover', 'meanwhile', 'her', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.832\n",
      "Bankruptcy roc_auc Train score: 1.000\n",
      "Bankruptcy roc_auc Test score: 0.996\n",
      "\n",
      "\n",
      "Tenant Failure: creating Train-Test split\n",
      "Number of distinct labeled tenant_failure document/sentence combinations within the full data set: 74\n",
      "Model fit in progress: {'target': 'tenant_failure', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 155.252\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 200, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': ['the', 'and', 'a', 'to', 'it', 'be', 'for', 'with', 'that', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.958\n",
      "Tenant Failure roc_auc Train score: 1.000\n",
      "Tenant Failure roc_auc Test score: 1.000\n",
      "\n",
      "\n",
      "Renovations: creating Train-Test split\n",
      "Number of distinct labeled renovations document/sentence combinations within the full data set: 26\n",
      "Model fit in progress: {'target': 'renovations', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 147.101\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 100, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['something', 'whereafter', 'are', 'full', 'of', 'neither', 'since', 'sixty', 'twelve', 'here', 'it', 'she', 'a', 'do', 'everyone', 'this', 'bottom', 'used', 'anywhere', 'never', 'the', 'mine', 'thru', 'either', 'give', 'serious', 'more', 'my', 'seems', 'just', 'i', 'formerly', 'namely', 'through', 'why', 'empty', 'yet', 'mostly', 'if', 'they', 'will', 'sometime', 'without', 'amount', 'get', 'has', 'nine', 'quite', 'does', 'though', 'whereupon', 'very', 'sometimes', 'whose', 'eleven', 'otherwise', 'side', 'made', 'me', 'hence', 'however', 'next', 'nor', 'whatever', 'third', 'themselves', 'seeming', 'him', 'back', 'did', 'herself', 'on', 'afterwards', 'their', 'thereupon', 'few', 'further', 'under', 'nobody', 'what', 'may', 'myself', 'then', 'again', 'around', 'that', 'after', 'keep', 'as', 'how', 'therein', 'behind', 'across', 're', 'down', 'really', 'alone', 'most', 'being', 'into', 'nowhere', 'among', 'its', 'ours', 'part', 'per', 'almost', 'below', 'we', 'forty', 'together', 'also', 'at', 'while', 'once', 'such', 'herein', 'else', 'both', 'go', 'front', 'already', 'there', 'unless', 'anyhow', 'his', 'ever', 'anything', 'indeed', 'although', 'call', 'before', 'nevertheless', 'each', 'those', 'an', 'whether', 'throughout', 'done', 'two', 'who', 'whole', 'rather', 'out', 'yours', 'take', 'another', 'ca', 'nothing', 'none', 'by', 'onto', 'any', 'between', 'over', 'much', 'eight', 'somewhere', 'be', 'first', 'latterly', 'towards', 'some', 'perhaps', 'amongst', 'whenever', 'wherever', 'everything', 'with', 'now', 'himself', 'these', 'which', 'for', 'in', 'was', 'would', 'them', 'all', 'hundred', 'not', 'even', 'yourselves', 'many', 'than', 'to', 'enough', 'hereafter', 'within', 'fifteen', 'beforehand', 'and', 'from', 'cannot', 'own', 'wherein', 'top', 'former', 'thereafter', 'he', 'several', 'say', 'us', 'our', 'along', 'someone', 'become', 'besides', 'fifty', 'itself', 'beyond', 'had', 'put', 'must', 'see', 'because', 'about', 'name', 'other', 'toward', 'where', 'five', 'via', 'various', 'whoever', 'off', 'can', 'whence', 'or', 'ourselves', 'noone', 'whereas', 'regarding', 'been', 'upon', 'hers', 'no', 'when', 'whereby', 'during', 'twenty', 'thereby', 'beside', 'have', 'seemed', 'often', 'hereby', 'please', 'same', 'ten', 'up', 'least', 'became', 'only', 'against', 'due', 'four', 'make', 'still', 'whom', 'latter', 'one', 'others', 'show', 'elsewhere', 'too', 'am', 'could', 'doing', 'last', 'should', 'every', 'were', 'using', 'seem', 'therefore', 'is', 'but', 'thence', 'except', 'three', 'less', 'anyone', 'move', 'well', 'your', 'somehow', 'becoming', 'everywhere', 'so', 'you', 'above', 'yourself', 'hereupon', 'until', 'becomes', 'anyway', 'always', 'thus', 'whither', 'might', 'six', 'moreover', 'meanwhile', 'her', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.756\n",
      "Renovations f1 Train score: 0.889\n",
      "Renovations f1 Test score: 0.933\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate Debt Yield Fall: creating Train-Test split\n",
      "Number of distinct labeled aggregate_debt_yield_fall document/sentence combinations within the full data set: 19\n",
      "Model fit in progress: {'target': 'aggregate_debt_yield_fall', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 147.594\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 600, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': ['the', 'and', 'a', 'to', 'it', 'be', 'for', 'with', 'that', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.546\n",
      "Aggregate Debt Yield Fall f1 Train score: 1.000\n",
      "Aggregate Debt Yield Fall f1 Test score: 0.800\n",
      "\n",
      "\n",
      "Dscr Fall: creating Train-Test split\n",
      "Number of distinct labeled dscr_fall document/sentence combinations within the full data set: 23\n",
      "Model fit in progress: {'target': 'dscr_fall', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 149.085\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['something', 'whereafter', 'are', 'full', 'of', 'neither', 'since', 'sixty', 'twelve', 'here', 'it', 'she', 'a', 'do', 'everyone', 'this', 'bottom', 'used', 'anywhere', 'never', 'the', 'mine', 'thru', 'either', 'give', 'serious', 'more', 'my', 'seems', 'just', 'i', 'formerly', 'namely', 'through', 'why', 'empty', 'yet', 'mostly', 'if', 'they', 'will', 'sometime', 'without', 'amount', 'get', 'has', 'nine', 'quite', 'does', 'though', 'whereupon', 'very', 'sometimes', 'whose', 'eleven', 'otherwise', 'side', 'made', 'me', 'hence', 'however', 'next', 'nor', 'whatever', 'third', 'themselves', 'seeming', 'him', 'back', 'did', 'herself', 'on', 'afterwards', 'their', 'thereupon', 'few', 'further', 'under', 'nobody', 'what', 'may', 'myself', 'then', 'again', 'around', 'that', 'after', 'keep', 'as', 'how', 'therein', 'behind', 'across', 're', 'down', 'really', 'alone', 'most', 'being', 'into', 'nowhere', 'among', 'its', 'ours', 'part', 'per', 'almost', 'below', 'we', 'forty', 'together', 'also', 'at', 'while', 'once', 'such', 'herein', 'else', 'both', 'go', 'front', 'already', 'there', 'unless', 'anyhow', 'his', 'ever', 'anything', 'indeed', 'although', 'call', 'before', 'nevertheless', 'each', 'those', 'an', 'whether', 'throughout', 'done', 'two', 'who', 'whole', 'rather', 'out', 'yours', 'take', 'another', 'ca', 'nothing', 'none', 'by', 'onto', 'any', 'between', 'over', 'much', 'eight', 'somewhere', 'be', 'first', 'latterly', 'towards', 'some', 'perhaps', 'amongst', 'whenever', 'wherever', 'everything', 'with', 'now', 'himself', 'these', 'which', 'for', 'in', 'was', 'would', 'them', 'all', 'hundred', 'not', 'even', 'yourselves', 'many', 'than', 'to', 'enough', 'hereafter', 'within', 'fifteen', 'beforehand', 'and', 'from', 'cannot', 'own', 'wherein', 'top', 'former', 'thereafter', 'he', 'several', 'say', 'us', 'our', 'along', 'someone', 'become', 'besides', 'fifty', 'itself', 'beyond', 'had', 'put', 'must', 'see', 'because', 'about', 'name', 'other', 'toward', 'where', 'five', 'via', 'various', 'whoever', 'off', 'can', 'whence', 'or', 'ourselves', 'noone', 'whereas', 'regarding', 'been', 'upon', 'hers', 'no', 'when', 'whereby', 'during', 'twenty', 'thereby', 'beside', 'have', 'seemed', 'often', 'hereby', 'please', 'same', 'ten', 'up', 'least', 'became', 'only', 'against', 'due', 'four', 'make', 'still', 'whom', 'latter', 'one', 'others', 'show', 'elsewhere', 'too', 'am', 'could', 'doing', 'last', 'should', 'every', 'were', 'using', 'seem', 'therefore', 'is', 'but', 'thence', 'except', 'three', 'less', 'anyone', 'move', 'well', 'your', 'somehow', 'becoming', 'everywhere', 'so', 'you', 'above', 'yourself', 'hereupon', 'until', 'becomes', 'anyway', 'always', 'thus', 'whither', 'might', 'six', 'moreover', 'meanwhile', 'her', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.617\n",
      "Dscr Fall f1 Train score: 1.000\n",
      "Dscr Fall f1 Test score: 0.750\n",
      "\n",
      "\n",
      "Operator Termination: creating Train-Test split\n",
      "Number of distinct labeled operator_termination document/sentence combinations within the full data set: 17\n",
      "Model fit in progress: {'target': 'operator_termination', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 142.463\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': ['something', 'whereafter', 'are', 'full', 'of', 'neither', 'since', 'sixty', 'twelve', 'here', 'it', 'she', 'a', 'do', 'everyone', 'this', 'bottom', 'used', 'anywhere', 'never', 'the', 'mine', 'thru', 'either', 'give', 'serious', 'more', 'my', 'seems', 'just', 'i', 'formerly', 'namely', 'through', 'why', 'empty', 'yet', 'mostly', 'if', 'they', 'will', 'sometime', 'without', 'amount', 'get', 'has', 'nine', 'quite', 'does', 'though', 'whereupon', 'very', 'sometimes', 'whose', 'eleven', 'otherwise', 'side', 'made', 'me', 'hence', 'however', 'next', 'nor', 'whatever', 'third', 'themselves', 'seeming', 'him', 'back', 'did', 'herself', 'on', 'afterwards', 'their', 'thereupon', 'few', 'further', 'under', 'nobody', 'what', 'may', 'myself', 'then', 'again', 'around', 'that', 'after', 'keep', 'as', 'how', 'therein', 'behind', 'across', 're', 'down', 'really', 'alone', 'most', 'being', 'into', 'nowhere', 'among', 'its', 'ours', 'part', 'per', 'almost', 'below', 'we', 'forty', 'together', 'also', 'at', 'while', 'once', 'such', 'herein', 'else', 'both', 'go', 'front', 'already', 'there', 'unless', 'anyhow', 'his', 'ever', 'anything', 'indeed', 'although', 'call', 'before', 'nevertheless', 'each', 'those', 'an', 'whether', 'throughout', 'done', 'two', 'who', 'whole', 'rather', 'out', 'yours', 'take', 'another', 'ca', 'nothing', 'none', 'by', 'onto', 'any', 'between', 'over', 'much', 'eight', 'somewhere', 'be', 'first', 'latterly', 'towards', 'some', 'perhaps', 'amongst', 'whenever', 'wherever', 'everything', 'with', 'now', 'himself', 'these', 'which', 'for', 'in', 'was', 'would', 'them', 'all', 'hundred', 'not', 'even', 'yourselves', 'many', 'than', 'to', 'enough', 'hereafter', 'within', 'fifteen', 'beforehand', 'and', 'from', 'cannot', 'own', 'wherein', 'top', 'former', 'thereafter', 'he', 'several', 'say', 'us', 'our', 'along', 'someone', 'become', 'besides', 'fifty', 'itself', 'beyond', 'had', 'put', 'must', 'see', 'because', 'about', 'name', 'other', 'toward', 'where', 'five', 'via', 'various', 'whoever', 'off', 'can', 'whence', 'or', 'ourselves', 'noone', 'whereas', 'regarding', 'been', 'upon', 'hers', 'no', 'when', 'whereby', 'during', 'twenty', 'thereby', 'beside', 'have', 'seemed', 'often', 'hereby', 'please', 'same', 'ten', 'up', 'least', 'became', 'only', 'against', 'due', 'four', 'make', 'still', 'whom', 'latter', 'one', 'others', 'show', 'elsewhere', 'too', 'am', 'could', 'doing', 'last', 'should', 'every', 'were', 'using', 'seem', 'therefore', 'is', 'but', 'thence', 'except', 'three', 'less', 'anyone', 'move', 'well', 'your', 'somehow', 'becoming', 'everywhere', 'so', 'you', 'above', 'yourself', 'hereupon', 'until', 'becomes', 'anyway', 'always', 'thus', 'whither', 'might', 'six', 'moreover', 'meanwhile', 'her', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.435\n",
      "Operator Termination f1 Train score: 0.957\n",
      "Operator Termination f1 Test score: 0.800\n",
      "\n",
      "\n",
      "Sponsor Termination: creating Train-Test split\n",
      "Number of distinct labeled sponsor_termination document/sentence combinations within the full data set: 14\n",
      "Model fit in progress: {'target': 'sponsor_termination', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 144.981\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['something', 'whereafter', 'are', 'full', 'of', 'neither', 'since', 'sixty', 'twelve', 'here', 'it', 'she', 'a', 'do', 'everyone', 'this', 'bottom', 'used', 'anywhere', 'never', 'the', 'mine', 'thru', 'either', 'give', 'serious', 'more', 'my', 'seems', 'just', 'i', 'formerly', 'namely', 'through', 'why', 'empty', 'yet', 'mostly', 'if', 'they', 'will', 'sometime', 'without', 'amount', 'get', 'has', 'nine', 'quite', 'does', 'though', 'whereupon', 'very', 'sometimes', 'whose', 'eleven', 'otherwise', 'side', 'made', 'me', 'hence', 'however', 'next', 'nor', 'whatever', 'third', 'themselves', 'seeming', 'him', 'back', 'did', 'herself', 'on', 'afterwards', 'their', 'thereupon', 'few', 'further', 'under', 'nobody', 'what', 'may', 'myself', 'then', 'again', 'around', 'that', 'after', 'keep', 'as', 'how', 'therein', 'behind', 'across', 're', 'down', 'really', 'alone', 'most', 'being', 'into', 'nowhere', 'among', 'its', 'ours', 'part', 'per', 'almost', 'below', 'we', 'forty', 'together', 'also', 'at', 'while', 'once', 'such', 'herein', 'else', 'both', 'go', 'front', 'already', 'there', 'unless', 'anyhow', 'his', 'ever', 'anything', 'indeed', 'although', 'call', 'before', 'nevertheless', 'each', 'those', 'an', 'whether', 'throughout', 'done', 'two', 'who', 'whole', 'rather', 'out', 'yours', 'take', 'another', 'ca', 'nothing', 'none', 'by', 'onto', 'any', 'between', 'over', 'much', 'eight', 'somewhere', 'be', 'first', 'latterly', 'towards', 'some', 'perhaps', 'amongst', 'whenever', 'wherever', 'everything', 'with', 'now', 'himself', 'these', 'which', 'for', 'in', 'was', 'would', 'them', 'all', 'hundred', 'not', 'even', 'yourselves', 'many', 'than', 'to', 'enough', 'hereafter', 'within', 'fifteen', 'beforehand', 'and', 'from', 'cannot', 'own', 'wherein', 'top', 'former', 'thereafter', 'he', 'several', 'say', 'us', 'our', 'along', 'someone', 'become', 'besides', 'fifty', 'itself', 'beyond', 'had', 'put', 'must', 'see', 'because', 'about', 'name', 'other', 'toward', 'where', 'five', 'via', 'various', 'whoever', 'off', 'can', 'whence', 'or', 'ourselves', 'noone', 'whereas', 'regarding', 'been', 'upon', 'hers', 'no', 'when', 'whereby', 'during', 'twenty', 'thereby', 'beside', 'have', 'seemed', 'often', 'hereby', 'please', 'same', 'ten', 'up', 'least', 'became', 'only', 'against', 'due', 'four', 'make', 'still', 'whom', 'latter', 'one', 'others', 'show', 'elsewhere', 'too', 'am', 'could', 'doing', 'last', 'should', 'every', 'were', 'using', 'seem', 'therefore', 'is', 'but', 'thence', 'except', 'three', 'less', 'anyone', 'move', 'well', 'your', 'somehow', 'becoming', 'everywhere', 'so', 'you', 'above', 'yourself', 'hereupon', 'until', 'becomes', 'anyway', 'always', 'thus', 'whither', 'might', 'six', 'moreover', 'meanwhile', 'her', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.357\n",
      "Sponsor Termination f1 Train score: 1.000\n",
      "Sponsor Termination f1 Test score: 0.857\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sff: creating Train-Test split\n",
      "Number of distinct labeled sff document/sentence combinations within the full data set: 9\n",
      "Model fit in progress: {'target': 'sff', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 147.548\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 100, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['the', 'and', 'a', 'to', 'it', 'be', 'for', 'with', 'that', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.222\n",
      "Sff f1 Train score: 0.800\n",
      "Sff f1 Test score: 0.000\n",
      "\n",
      "\n",
      "Mezzanine Outstanding: creating Train-Test split\n",
      "Number of distinct labeled mezzanine_outstanding document/sentence combinations within the full data set: 8\n",
      "Model fit in progress: {'target': 'mezzanine_outstanding', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 143.265\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 400, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 4), 'cvec__stop_words': ['the', 'and', 'a', 'to', 'it', 'be', 'for', 'with', 'that', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.389\n",
      "Mezzanine Outstanding f1 Train score: 0.909\n",
      "Mezzanine Outstanding f1 Test score: 0.000\n",
      "\n",
      "\n",
      "Aggregate Dscr Fall: creating Train-Test split\n",
      "Number of distinct labeled aggregate_dscr_fall document/sentence combinations within the full data set: 8\n",
      "Model fit in progress: {'target': 'aggregate_dscr_fall', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
      "Seconds elapsed for fitting: 143.342\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 100, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['the', 'to', 'of', 'be', 'and', 'in', 'a', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 1.000\n",
      "Aggregate Dscr Fall f1 Train score: 1.000\n",
      "Aggregate Dscr Fall f1 Test score: 0.000\n",
      "\n",
      "\n",
      "Delayed Repayment: creating Train-Test split\n",
      "Number of distinct labeled delayed_repayment document/sentence combinations within the full data set: 3\n",
      "Model fit in progress: {'target': 'delayed_repayment', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds elapsed for fitting: 141.386\n",
      "Best fit parameters: {'cvec__max_df': 0.99, 'cvec__max_features': 100, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['the', 'to', 'of', 'be', 'and', 'in', 'a', 'marriott']}\n",
      "Best fit 3-fold cross validation score: 0.000\n",
      "Delayed Repayment f1 Train score: 1.000\n",
      "Delayed Repayment f1 Test score: 0.000\n",
      "\n",
      "\n",
      "Modeling complete!\n"
     ]
    }
   ],
   "source": [
    "# Control of the main project\n",
    "\n",
    "# define dictionary of targets contains: tag, model, metric, input, order\n",
    "target_dict = {}\n",
    "target_dict['nontrigger'] = {'target': 'nontrigger', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['loan_default'] = {'target': 'loan_default', 'model': 'lr', 'metric':'roc_auc', 'model_input':'SentenceLemmas'}\n",
    "target_dict['unspecified'] = {'target': 'unspecified', 'model': 'lr', 'metric':'roc_auc', 'model_input':'SentenceLemmas'}\n",
    "target_dict['debt_yield_fall'] = {'target': 'debt_yield_fall', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['mezzanine_default'] = {'target': 'mezzanine_default', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['bankruptcy'] = {'target': 'bankruptcy', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['tenant_failure'] = {'target': 'tenant_failure', 'model': 'lr', 'metric': 'roc_auc', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['renovations'] = {'target': 'renovations', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['aggregate_debt_yield_fall'] = {'target': 'aggregate_debt_yield_fall', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['dscr_fall'] = {'target': 'dscr_fall', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['operator_termination'] = {'target': 'operator_termination', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['sponsor_termination'] = {'target': 'sponsor_termination', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['sff'] = {'target': 'sff', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['mezzanine_outstanding'] = {'target': 'mezzanine_outstanding', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['aggregate_dscr_fall'] = {'target': 'aggregate_dscr_fall', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
    "target_dict['delayed_repayment'] = {'target': 'delayed_repayment', 'model': 'lr', 'metric': 'f1', 'model_input': 'SentenceLemmas'}\n",
    "\n",
    "\n",
    "# set output_dict - will contain target + output of calculations\n",
    "output_dict = {}\n",
    "\n",
    "# get data\n",
    "df = get_reshaped_lemmatized()\n",
    "\n",
    "# run for each model definition\n",
    "for k,v in target_dict.items():\n",
    "    \n",
    "    print(f\"{target_dict[k]['target'].replace('_', ' ').title()}: creating Train-Test split\")\n",
    "    # get split data\n",
    "    split_data = get_split_data(df, v)\n",
    "    \n",
    "    print(f\"Model fit in progress: {target_dict[k]}\")\n",
    "    # run model\n",
    "    model_result = run_model(split_data, v)\n",
    "    \n",
    "    # make the output dictionary\n",
    "    output_dict[k] = v\n",
    "    output_dict[k]['split_data'] = split_data\n",
    "    output_dict[k]['model_result'] = model_result\n",
    "\n",
    "    \n",
    "    print(f\"Best fit parameters: {model_result.best_params_}\")\n",
    "    print(f\"Best fit 3-fold cross validation score: {model_result.best_score_:.3f}\")\n",
    "    print(f\"{target_dict[k]['target'].replace('_', ' ').title()} {target_dict[k]['metric']} Train score: {model_result.score(split_data['X_train'], split_data['y_train']):.3f}\")\n",
    "    print(f\"{target_dict[k]['target'].replace('_', ' ').title()} {target_dict[k]['metric']} Test score: {model_result.score(split_data['X_test'], split_data['y_test']):.3f}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    output_dict[k]['best_params'] = model_result.best_params_\n",
    "    output_dict[k]['count_deduplicated'] = df[target_dict[k]['target']].value_counts()[1]\n",
    "    output_dict[k]['test_data_count'] = output_dict[k]['split_data']['y_test'].value_counts()[1]\n",
    "    output_dict[k]['best_crossval_score'] = model_result.best_score_\n",
    "    output_dict[k]['train_score'] = model_result.score(split_data['X_train'], split_data['y_train'])\n",
    "    output_dict[k]['test_score'] = model_result.score(split_data['X_test'], split_data['y_test'])                                                  \n",
    "    \n",
    "    '''\n",
    "    outfile = open(f\"../data/models/{target_dict[k]['target']}_pickle\", 'wb')\n",
    "    pickle.dump(model_result, outfile)\n",
    "    outfile.close()\n",
    "    '''\n",
    "    \n",
    "\n",
    "full_output_dict = [output_dict[key] for key in output_dict.keys()]\n",
    "results_df = pd.DataFrame.from_dict(full_output_dict)\n",
    "\n",
    "# Export summary table\n",
    "results_df.to_csv(f'../data/exported_data/results_df_fulldata.csv')\n",
    "\n",
    "print(\"Modeling complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>model_input</th>\n",
       "      <th>split_data</th>\n",
       "      <th>model_result</th>\n",
       "      <th>best_params</th>\n",
       "      <th>count_deduplicated</th>\n",
       "      <th>test_data_count</th>\n",
       "      <th>best_crossval_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nontrigger</td>\n",
       "      <td>lr</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': [' trigger period mean a period a ...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>1030</td>\n",
       "      <td>309</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.985937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loan_default</td>\n",
       "      <td>lr</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['upon the occurrence of a lockbox...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 4...</td>\n",
       "      <td>553</td>\n",
       "      <td>166</td>\n",
       "      <td>0.982374</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>0.991220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unspecified</td>\n",
       "      <td>lr</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['any fund remain in the reserve a...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>498</td>\n",
       "      <td>149</td>\n",
       "      <td>0.965063</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.964248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debt_yield_fall</td>\n",
       "      <td>lr</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': [' approve operating expense mean ...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 2...</td>\n",
       "      <td>188</td>\n",
       "      <td>56</td>\n",
       "      <td>0.974742</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.997085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mezzanine_default</td>\n",
       "      <td>lr</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['borrower hereby represent and wa...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>72</td>\n",
       "      <td>22</td>\n",
       "      <td>0.949262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bankruptcy</td>\n",
       "      <td>lr</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['hard lockbox and spring cash man...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 2...</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>0.832279</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.995529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tenant_failure</td>\n",
       "      <td>lr</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['follow the occurrence and prior ...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 2...</td>\n",
       "      <td>74</td>\n",
       "      <td>22</td>\n",
       "      <td>0.957538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>renovations</td>\n",
       "      <td>lr</td>\n",
       "      <td>f1</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['see description of the mortgage ...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aggregate_debt_yield_fall</td>\n",
       "      <td>lr</td>\n",
       "      <td>f1</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['the mortgage lender will make di...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 6...</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0.546032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dscr_fall</td>\n",
       "      <td>lr</td>\n",
       "      <td>f1</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['upon the write request of mortga...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>operator_termination</td>\n",
       "      <td>lr</td>\n",
       "      <td>f1</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['the follow reserve be require to...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.434921</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sponsor_termination</td>\n",
       "      <td>lr</td>\n",
       "      <td>f1</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['a trigger period as more fully d...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sff</td>\n",
       "      <td>lr</td>\n",
       "      <td>f1</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['the mortgage loan documents requ...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mezzanine_outstanding</td>\n",
       "      <td>lr</td>\n",
       "      <td>f1</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['the mortgage lender will not be ...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 4...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aggregate_dscr_fall</td>\n",
       "      <td>lr</td>\n",
       "      <td>f1</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': ['under the term of the mortgage l...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>delayed_repayment</td>\n",
       "      <td>lr</td>\n",
       "      <td>f1</td>\n",
       "      <td>SentenceLemmas</td>\n",
       "      <td>{'X_train': [' cash trap period mean the perio...</td>\n",
       "      <td>GridSearchCV(cv=3, error_score=nan,\\n         ...</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 1...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       target model   metric     model_input  \\\n",
       "0                  nontrigger    lr  roc_auc  SentenceLemmas   \n",
       "1                loan_default    lr  roc_auc  SentenceLemmas   \n",
       "2                 unspecified    lr  roc_auc  SentenceLemmas   \n",
       "3             debt_yield_fall    lr  roc_auc  SentenceLemmas   \n",
       "4           mezzanine_default    lr  roc_auc  SentenceLemmas   \n",
       "5                  bankruptcy    lr  roc_auc  SentenceLemmas   \n",
       "6              tenant_failure    lr  roc_auc  SentenceLemmas   \n",
       "7                 renovations    lr       f1  SentenceLemmas   \n",
       "8   aggregate_debt_yield_fall    lr       f1  SentenceLemmas   \n",
       "9                   dscr_fall    lr       f1  SentenceLemmas   \n",
       "10       operator_termination    lr       f1  SentenceLemmas   \n",
       "11        sponsor_termination    lr       f1  SentenceLemmas   \n",
       "12                        sff    lr       f1  SentenceLemmas   \n",
       "13      mezzanine_outstanding    lr       f1  SentenceLemmas   \n",
       "14        aggregate_dscr_fall    lr       f1  SentenceLemmas   \n",
       "15          delayed_repayment    lr       f1  SentenceLemmas   \n",
       "\n",
       "                                           split_data  \\\n",
       "0   {'X_train': [' trigger period mean a period a ...   \n",
       "1   {'X_train': ['upon the occurrence of a lockbox...   \n",
       "2   {'X_train': ['any fund remain in the reserve a...   \n",
       "3   {'X_train': [' approve operating expense mean ...   \n",
       "4   {'X_train': ['borrower hereby represent and wa...   \n",
       "5   {'X_train': ['hard lockbox and spring cash man...   \n",
       "6   {'X_train': ['follow the occurrence and prior ...   \n",
       "7   {'X_train': ['see description of the mortgage ...   \n",
       "8   {'X_train': ['the mortgage lender will make di...   \n",
       "9   {'X_train': ['upon the write request of mortga...   \n",
       "10  {'X_train': ['the follow reserve be require to...   \n",
       "11  {'X_train': ['a trigger period as more fully d...   \n",
       "12  {'X_train': ['the mortgage loan documents requ...   \n",
       "13  {'X_train': ['the mortgage lender will not be ...   \n",
       "14  {'X_train': ['under the term of the mortgage l...   \n",
       "15  {'X_train': [' cash trap period mean the perio...   \n",
       "\n",
       "                                         model_result  \\\n",
       "0   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "1   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "2   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "3   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "4   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "5   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "6   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "7   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "8   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "9   GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "10  GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "11  GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "12  GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "13  GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "14  GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "15  GridSearchCV(cv=3, error_score=nan,\\n         ...   \n",
       "\n",
       "                                          best_params  count_deduplicated  \\\n",
       "0   {'cvec__max_df': 0.99, 'cvec__max_features': 1...                1030   \n",
       "1   {'cvec__max_df': 0.99, 'cvec__max_features': 4...                 553   \n",
       "2   {'cvec__max_df': 0.99, 'cvec__max_features': 1...                 498   \n",
       "3   {'cvec__max_df': 0.99, 'cvec__max_features': 2...                 188   \n",
       "4   {'cvec__max_df': 0.99, 'cvec__max_features': 1...                  72   \n",
       "5   {'cvec__max_df': 0.99, 'cvec__max_features': 2...                  44   \n",
       "6   {'cvec__max_df': 0.99, 'cvec__max_features': 2...                  74   \n",
       "7   {'cvec__max_df': 0.99, 'cvec__max_features': 1...                  26   \n",
       "8   {'cvec__max_df': 0.99, 'cvec__max_features': 6...                  19   \n",
       "9   {'cvec__max_df': 0.99, 'cvec__max_features': 1...                  23   \n",
       "10  {'cvec__max_df': 0.99, 'cvec__max_features': 1...                  17   \n",
       "11  {'cvec__max_df': 0.99, 'cvec__max_features': 1...                  14   \n",
       "12  {'cvec__max_df': 0.99, 'cvec__max_features': 1...                   9   \n",
       "13  {'cvec__max_df': 0.99, 'cvec__max_features': 4...                   8   \n",
       "14  {'cvec__max_df': 0.99, 'cvec__max_features': 1...                   8   \n",
       "15  {'cvec__max_df': 0.99, 'cvec__max_features': 1...                   3   \n",
       "\n",
       "    test_data_count  best_crossval_score  train_score  test_score  \n",
       "0               309             0.986957     0.999823    0.985937  \n",
       "1               166             0.982374     0.999221    0.991220  \n",
       "2               149             0.965063     0.999828    0.964248  \n",
       "3                56             0.974742     0.999959    0.997085  \n",
       "4                22             0.949262     1.000000    0.994850  \n",
       "5                13             0.832279     0.999897    0.995529  \n",
       "6                22             0.957538     1.000000    0.999863  \n",
       "7                 8             0.755556     0.888889    0.933333  \n",
       "8                 6             0.546032     1.000000    0.800000  \n",
       "9                 7             0.616667     1.000000    0.750000  \n",
       "10                5             0.434921     0.956522    0.800000  \n",
       "11                4             0.357143     1.000000    0.857143  \n",
       "12                3             0.222222     0.800000    0.000000  \n",
       "13                2             0.388889     0.909091    0.000000  \n",
       "14                2             1.000000     1.000000    0.000000  \n",
       "15                1             0.000000     1.000000    0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results of modeling (already exported as 'results_df_fulldata.csv')\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the model details\n",
    "path = '../data/exported_data/'\n",
    "outfile = open(path + 'results_df_notebook2.pkl', 'wb')\n",
    "pickle.dump(results_df, outfile)\n",
    "outfile.close()\n",
    "\n",
    "outfile = open(path + 'full_output_dict_notebook2.pkl', 'wb')\n",
    "pickle.dump(full_output_dict, outfile)\n",
    "outfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
