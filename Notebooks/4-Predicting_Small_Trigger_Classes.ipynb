{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Predicting Small Trigger Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook focuses on the smaller classes. We aim to determine whether a custom sampling method can improve identification and predictions of the smaller classes. To achieve this, we create a test set that consists of evenly sampled selections of the larger classes. This becomes our \"Is Trigger\" set, and we balance this with an equivalently sized \"Not Trigger\" set. We then make predictions on the remaining data.\n",
    "\n",
    "Steps performed by the included functions:\n",
    "- import the reshaped and lemmatized data from Notebook 1\n",
    "- Create a custom training set by downsampling the larger classes, and balancing with an equivalent amount of Nontetrigger sentences\n",
    "- Fit the data via logistic regression & review model performance against the Test data set, containing the unseen Trigger categories\n",
    "- Calculate the percentage of unseen Trigger categories that were correctly predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(99)\n",
    "RANDOM_STATE = 99\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reshaped_lemmatized():\n",
    "    # Import the CSV file containing the reshaped data set\n",
    "    df = pd.read_csv('../data/reshaped_lemmatized.csv').drop(columns = ('Unnamed: 0'), axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling_data_set(df, threshold):\n",
    "    '''This function creates custom classes for our training and test set. The training set consists \n",
    "    of evenly sampled number of each of the larger classes (chosen via the variable 'threshold'). \n",
    "    All remaining data (including the small classes) becomes the test set.'''\n",
    "    #Total sum per row: \n",
    "    downsampling_set = df\n",
    "    downsampling_set.loc[:,'Total'] = downsampling_set.sum(axis=1)\n",
    "\n",
    "    # select only Sentences with 1 or 2 triggers\n",
    "    downsampling_set = downsampling_set[downsampling_set['Total'].isin([1,2])]\n",
    "\n",
    "    \n",
    "    # isolate the trigger columns to sample from \n",
    "    # (only includes trigger types that exist in more than the threhold number of sentences)\n",
    "    n = threshold\n",
    "    trigger_cols = downsampling_set.drop(['Document', 'Sentence', 'SentenceLemmas', 'SentenceTokens'], axis=1).sum(axis=0)\n",
    "    trigger_cols = trigger_cols.where(lambda x: x > n).dropna() # Skip types that occur less than the threshold amount\n",
    "    trigger_cols = [t for t in list(trigger_cols.index) if t not in ['Total', 'nontrigger', 'unspecified']]\n",
    "    nontrigger_cols = ['nontrigger']\n",
    "    \n",
    "    # randomly sample n rows from the selected trigger columns without replacement - samples is the training set\n",
    "    init = True\n",
    "\n",
    "    # Randomly sample the threshold amount of instances for each of the larger trigger classes\n",
    "    for col in trigger_cols:\n",
    "        temp_col = downsampling_set[downsampling_set[col] == 1]\n",
    "        sampled_col = resample(temp_col, replace = False, n_samples = n, random_state = RANDOM_STATE)\n",
    "        if init:\n",
    "            samples = sampled_col\n",
    "            init = False\n",
    "        else:\n",
    "            samples = pd.concat([samples,sampled_col])\n",
    "            \n",
    "    n_unspecified = samples.shape[0] # Prepare to randomly collect nontrigger data of an equivalent size\n",
    "    # Randomly sample an equivalently sized set of nontrigger data\n",
    "    for col in nontrigger_cols:\n",
    "        temp_col = downsampling_set[downsampling_set[col] == 1]\n",
    "        nontrigger_sampled_col = resample(temp_col, replace = False, n_samples = n_unspecified, random_state = RANDOM_STATE)\n",
    "        samples = pd.concat([samples, nontrigger_sampled_col])\n",
    "        \n",
    "    # remove these rows from the main data set - select index and remove by index (call new set \"filtered\")\n",
    "    rmv_index = list(samples.index)\n",
    "    filtered = df.drop(rmv_index, axis='index') # This will become our Test Set\n",
    "    \n",
    "    # make 'is trigger' column\n",
    "    samples['istrigger'] = np.where(samples['nontrigger'] > 0, 0, 1)\n",
    "    filtered['istrigger'] = np.where(filtered['nontrigger'] > 0, 0, 1)\n",
    "    \n",
    "    # Check which trigger types were included in the training set\n",
    "    in_train_set = (downsampling_set.drop(['Document', 'Sentence', 'Total', 'unspecified','SentenceLemmas', 'SentenceTokens'], axis=1).sum(axis=0) > n).to_frame()\n",
    "    \n",
    "    return samples, filtered, in_train_set # Samples will be the Training Set, Filtered will be the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate Stopwords\n",
    "def get_stopwords():\n",
    "    '''This function includes the creation/usage of various Stopword lists, which can be modified as needed.'''\n",
    "    short_stopwords = ['the', 'to', 'of', 'be', 'and', 'in', 'a', 'marriott']\n",
    "    short_stopwords2 = ['the', 'and', 'a', 'to', 'it', 'be', 'for', 'with', 'that', 'marriott']\n",
    "    stopwords = list(STOP_WORDS) + ['marriott']\n",
    "\n",
    "    return short_stopwords, short_stopwords2, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data for each target column (trigger type) \n",
    "def run_model(df, threshold):\n",
    "    '''This function carries out the Logistic Regression modeling for the custom dataset, \n",
    "    with the GridSearch set of hyperparameters defined below'''\n",
    "    downsampling_data_set(df, threshold)\n",
    "    short_stopwords, short_stopwords2, stopwords = get_stopwords()\n",
    "    \n",
    "    X_train = samples['SentenceLemmas']\n",
    "    y_train = samples['istrigger']\n",
    "    X_test = filtered['SentenceLemmas']\n",
    "    y_test = filtered['istrigger']\n",
    "\n",
    "    y_train = y_train.astype('int')\n",
    "    y_test = y_test.astype('int')\n",
    "\n",
    "    \n",
    "    train_index = samples.index\n",
    "    test_index = filtered.index\n",
    "    \n",
    "    pipe_cvec = Pipeline([('cvec', CountVectorizer()), ('lr', LogisticRegression(solver = 'liblinear', random_state = RANDOM_STATE))]) \n",
    "    cvec_params = {\n",
    "        'cvec__ngram_range': [(1,2), (1,3), (1,4), (1,5)],\n",
    "        'cvec__stop_words': [short_stopwords, short_stopwords2, stopwords],  \n",
    "        'cvec__max_features': [100, 200, 400, 600, 1000],\n",
    "        'cvec__min_df': [2],\n",
    "        'cvec__max_df': [.99],\n",
    "        }\n",
    "\n",
    "    gs_cvec = GridSearchCV(pipe_cvec, param_grid = cvec_params, cv = 3, scoring = 'roc_auc')\n",
    "\n",
    "    # Fit the data set (predicting \"istrigger\" yes/no)\n",
    "    results_cvec = gs_cvec.fit(X_train, y_train)\n",
    "\n",
    "    # Print Train/Test Scores\n",
    "    print(f'Training score is {results_cvec.score(X_train, y_train):.3f}')\n",
    "    print(f'Test score is {results_cvec.score(X_test, y_test):.3f}')\n",
    "    \n",
    "    return results_cvec, X_train, y_train, X_test, y_test, train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassification(results_cvec, X_train, y_train, X_test, y_test, train_index, test_index, filtered):\n",
    "    '''This function creates a view of the misclassified predictions for each of the trigger categories.\n",
    "    From here, we can calculate how many of the small classes (excluded from the training set) were\n",
    "    correctly predicted.'''\n",
    "    best_model = results_cvec.best_estimator_\n",
    "    preds = best_model.predict(X_test)\n",
    "    pred_proba = [i[1] for i in results_cvec.predict_proba(X_test)]\n",
    "    pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})\n",
    "    result_cols = ['index', 'prediction', 'actual', 'model_input']\n",
    "    results = pd.DataFrame({'index': list(test_index),'prediction': list(preds), 'actual': list(y_test), 'model_input': list(X_test)})\n",
    "    results.set_index('index', inplace = True)\n",
    "    misclassified = results[results['prediction'] != results['actual']]\n",
    "    misclassified = misclassified.merge(df, how = 'left', left_index = True, right_index = True)\n",
    "    misclassified = misclassified[['prediction', 'actual', 'model_input', 'Document', 'Sentence', 'loan_default', 'aggregate_dscr_fall', 'dscr_fall', 'unspecified', 'debt_yield_fall', 'aggregate_debt_yield_fall', 'mezzanine_default', 'tenant_failure', 'mezzanine_outstanding', 'operator_termination', 'bankruptcy', 'sponsor_termination', 'renovations', 'nontrigger', 'sff', 'delayed_repayment']]\n",
    "    full_test_set = filtered.drop(['Document', 'Sentence', 'Total', 'istrigger', 'SentenceTokens', 'SentenceLemmas'], axis = 1).sum(axis = 0).to_frame()\n",
    "    misclassified_test_set = misclassified.drop(['prediction', 'actual', 'Document', 'Sentence', 'model_input'], axis=1).sum(axis=0).to_frame()\n",
    "    misclassified_results = full_test_set.merge(misclassified_test_set, left_index = True, right_index = True)\n",
    "    misclassified_results.rename(columns = {'0_x': 'full_test_set', '0_y': 'num_misclassified'}, inplace = True)\n",
    "    misclassified_results['percent_misclassified'] = 100 * misclassified_results['num_misclassified'] / misclassified_results['full_test_set']\n",
    "    misclassified_results['percent_misclassified'] = misclassified_results['percent_misclassified'].round(1)\n",
    "    misclassified_results = misclassified_results.merge(in_train_set, left_index = True, right_index = True)\n",
    "    misclassified_results.rename(columns = {0: 'in_train_set'}, inplace = True)\n",
    "    misclassified_results['in_train_set'] = misclassified_results['in_train_set'].map({True: 'yes', False: 'no'})\n",
    "    return misclassified_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform modeling steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the above functions, in which we have created a custom training set that consists of evenly sampled selections of the largest classes. We then test how well that model performs against all remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is 1.000\n",
      "Test score is 0.911\n"
     ]
    }
   ],
   "source": [
    "df = get_reshaped_lemmatized()\n",
    "samples, filtered, in_train_set = downsampling_data_set(df, 10)\n",
    "results_cvec, X_train, y_train, X_test, y_test, train_index, test_index = run_model(df, 10)\n",
    "misclassified_results = misclassification(results_cvec, X_train, y_train, X_test, y_test, train_index, test_index, filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.4% of the small classes were predicted correctly.\n"
     ]
    }
   ],
   "source": [
    "small_class_predict_correct = 1-(misclassified_results[misclassified_results['in_train_set']== 'no'].sum(axis = 0)['num_misclassified'])/ misclassified_results[misclassified_results['in_train_set']== 'no'].sum(axis = 0)['full_test_set']\n",
    "print(f'{100 *small_class_predict_correct:.1f}% of the small classes were predicted correctly.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_test_set</th>\n",
       "      <th>num_misclassified</th>\n",
       "      <th>percent_misclassified</th>\n",
       "      <th>in_train_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_default</th>\n",
       "      <td>524</td>\n",
       "      <td>37</td>\n",
       "      <td>7.1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregate_dscr_fall</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dscr_fall</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debt_yield_fall</th>\n",
       "      <td>171</td>\n",
       "      <td>10</td>\n",
       "      <td>5.8</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregate_debt_yield_fall</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mezzanine_default</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenant_failure</th>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mezzanine_outstanding</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>28.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operator_termination</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bankruptcy</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sponsor_termination</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renovations</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>18.8</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nontrigger</th>\n",
       "      <td>940</td>\n",
       "      <td>40</td>\n",
       "      <td>4.3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sff</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>22.2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delayed_repayment</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           full_test_set  num_misclassified  \\\n",
       "loan_default                         524                 37   \n",
       "aggregate_dscr_fall                    7                  0   \n",
       "dscr_fall                             13                  0   \n",
       "debt_yield_fall                      171                 10   \n",
       "aggregate_debt_yield_fall              9                  0   \n",
       "mezzanine_default                     62                  0   \n",
       "tenant_failure                        64                  6   \n",
       "mezzanine_outstanding                  7                  2   \n",
       "operator_termination                   7                  0   \n",
       "bankruptcy                            44                  2   \n",
       "sponsor_termination                    4                  0   \n",
       "renovations                           16                  3   \n",
       "nontrigger                           940                 40   \n",
       "sff                                    9                  2   \n",
       "delayed_repayment                      3                  0   \n",
       "\n",
       "                           percent_misclassified in_train_set  \n",
       "loan_default                                 7.1          yes  \n",
       "aggregate_dscr_fall                          0.0           no  \n",
       "dscr_fall                                    0.0          yes  \n",
       "debt_yield_fall                              5.8          yes  \n",
       "aggregate_debt_yield_fall                    0.0          yes  \n",
       "mezzanine_default                            0.0          yes  \n",
       "tenant_failure                               9.4          yes  \n",
       "mezzanine_outstanding                       28.6           no  \n",
       "operator_termination                         0.0          yes  \n",
       "bankruptcy                                   4.5           no  \n",
       "sponsor_termination                          0.0          yes  \n",
       "renovations                                 18.8          yes  \n",
       "nontrigger                                   4.3          yes  \n",
       "sff                                         22.2           no  \n",
       "delayed_repayment                            0.0           no  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a summary table of the results\n",
    "misclassified_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
